{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "tWwA0zAwE56A"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "df = pd.read_excel('/Foodwatch_input_data.xlsx')\n",
        "df[['Crop_Cover_Percentage', 'Normalized_Food_Price', 'GDP_Per_Capita', 'Pests', 'Transport_Network_Density', 'Food_Storage_Groceries', 'Conflict_Per_Capita', 'Food_Wastage_Per_Capita']] = scaler.fit_transform(df[['Crop_Cover_Percentage', 'Normalized_Food_Price', 'GDP_Per_Capita', 'Pests', 'Transport_Network_Density', 'Food_Storage_Groceries', 'Conflict_Per_Capita', 'Food_Wastage_Per_Capita']])\n",
        "two_factors = df.loc[:, ['Food_Wastage_Per_Capita', 'Conflict_Per_Capita', 'Region', 'IPC_Level']]\n",
        "\n"
      ],
      "metadata": {
        "id": "-LB1KZ7uGFH4"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the Data\n",
        "X = two_factors.drop(['Region', 'IPC_Level'], axis=1)\n",
        "y = two_factors['IPC_Level']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "X1_C_7FbH3xT"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create PyTorch Dataset and DataLoader\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X.values, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y.values, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "GiAyHJaMLos0"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "KsA5fKnKL9fR"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Neural Network Architecture\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "h7nWFdtDMAJK"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork(input_size=X_train.shape[1])"
      ],
      "metadata": {
        "id": "gFBiUwJKNIPS"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Loss Function and Optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "BbtuPOWMNLyZ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the Model\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for inputs, targets in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs.squeeze(), targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsSH1is1NOM4",
        "outputId": "5271a365-106d-4f49-ffac-3151e5101625"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Loss: 4.268941879272461\n",
            "Epoch [2/100], Loss: 0.6259691119194031\n",
            "Epoch [3/100], Loss: 0.8757810592651367\n",
            "Epoch [4/100], Loss: 0.5550104379653931\n",
            "Epoch [5/100], Loss: 0.3604367673397064\n",
            "Epoch [6/100], Loss: 0.35836511850357056\n",
            "Epoch [7/100], Loss: 0.23980361223220825\n",
            "Epoch [8/100], Loss: 0.3150872588157654\n",
            "Epoch [9/100], Loss: 0.3395639955997467\n",
            "Epoch [10/100], Loss: 0.19104652106761932\n",
            "Epoch [11/100], Loss: 0.19297951459884644\n",
            "Epoch [12/100], Loss: 0.3198612928390503\n",
            "Epoch [13/100], Loss: 0.30448293685913086\n",
            "Epoch [14/100], Loss: 0.26447200775146484\n",
            "Epoch [15/100], Loss: 0.16132698953151703\n",
            "Epoch [16/100], Loss: 0.21708062291145325\n",
            "Epoch [17/100], Loss: 0.1927681863307953\n",
            "Epoch [18/100], Loss: 0.2632829248905182\n",
            "Epoch [19/100], Loss: 0.37921321392059326\n",
            "Epoch [20/100], Loss: 0.2321217805147171\n",
            "Epoch [21/100], Loss: 0.2070484459400177\n",
            "Epoch [22/100], Loss: 0.11587405204772949\n",
            "Epoch [23/100], Loss: 0.2609114944934845\n",
            "Epoch [24/100], Loss: 0.27991124987602234\n",
            "Epoch [25/100], Loss: 0.4236312508583069\n",
            "Epoch [26/100], Loss: 0.23727302253246307\n",
            "Epoch [27/100], Loss: 0.24426208436489105\n",
            "Epoch [28/100], Loss: 0.19061636924743652\n",
            "Epoch [29/100], Loss: 0.26459264755249023\n",
            "Epoch [30/100], Loss: 0.5974454879760742\n",
            "Epoch [31/100], Loss: 0.305077463388443\n",
            "Epoch [32/100], Loss: 0.2928701937198639\n",
            "Epoch [33/100], Loss: 0.3171992003917694\n",
            "Epoch [34/100], Loss: 0.47758185863494873\n",
            "Epoch [35/100], Loss: 0.20699357986450195\n",
            "Epoch [36/100], Loss: 0.3876928389072418\n",
            "Epoch [37/100], Loss: 0.14497847855091095\n",
            "Epoch [38/100], Loss: 0.15962742269039154\n",
            "Epoch [39/100], Loss: 0.3187781572341919\n",
            "Epoch [40/100], Loss: 0.3611513674259186\n",
            "Epoch [41/100], Loss: 0.2637069821357727\n",
            "Epoch [42/100], Loss: 0.2712927460670471\n",
            "Epoch [43/100], Loss: 0.16772150993347168\n",
            "Epoch [44/100], Loss: 0.3473167419433594\n",
            "Epoch [45/100], Loss: 0.1808023750782013\n",
            "Epoch [46/100], Loss: 0.31055131554603577\n",
            "Epoch [47/100], Loss: 0.26006075739860535\n",
            "Epoch [48/100], Loss: 0.29184138774871826\n",
            "Epoch [49/100], Loss: 0.41782525181770325\n",
            "Epoch [50/100], Loss: 0.23722222447395325\n",
            "Epoch [51/100], Loss: 0.2987603545188904\n",
            "Epoch [52/100], Loss: 0.2084556370973587\n",
            "Epoch [53/100], Loss: 0.19736461341381073\n",
            "Epoch [54/100], Loss: 0.3764877915382385\n",
            "Epoch [55/100], Loss: 0.3611264228820801\n",
            "Epoch [56/100], Loss: 0.4815644919872284\n",
            "Epoch [57/100], Loss: 0.22514702379703522\n",
            "Epoch [58/100], Loss: 0.233646422624588\n",
            "Epoch [59/100], Loss: 0.1676110029220581\n",
            "Epoch [60/100], Loss: 0.20851834118366241\n",
            "Epoch [61/100], Loss: 0.26491478085517883\n",
            "Epoch [62/100], Loss: 0.5031644105911255\n",
            "Epoch [63/100], Loss: 0.32565268874168396\n",
            "Epoch [64/100], Loss: 0.2715815007686615\n",
            "Epoch [65/100], Loss: 0.2596267759799957\n",
            "Epoch [66/100], Loss: 0.39164844155311584\n",
            "Epoch [67/100], Loss: 0.13325585424900055\n",
            "Epoch [68/100], Loss: 0.20227748155593872\n",
            "Epoch [69/100], Loss: 0.5522584319114685\n",
            "Epoch [70/100], Loss: 0.21639080345630646\n",
            "Epoch [71/100], Loss: 0.2759297490119934\n",
            "Epoch [72/100], Loss: 0.15519613027572632\n",
            "Epoch [73/100], Loss: 0.3221413493156433\n",
            "Epoch [74/100], Loss: 0.15502934157848358\n",
            "Epoch [75/100], Loss: 0.2304311841726303\n",
            "Epoch [76/100], Loss: 0.12895776331424713\n",
            "Epoch [77/100], Loss: 0.19479437172412872\n",
            "Epoch [78/100], Loss: 0.35718870162963867\n",
            "Epoch [79/100], Loss: 0.3496609628200531\n",
            "Epoch [80/100], Loss: 0.1719253957271576\n",
            "Epoch [81/100], Loss: 0.3449185788631439\n",
            "Epoch [82/100], Loss: 0.3189085125923157\n",
            "Epoch [83/100], Loss: 0.26417648792266846\n",
            "Epoch [84/100], Loss: 0.24998079240322113\n",
            "Epoch [85/100], Loss: 0.36188802123069763\n",
            "Epoch [86/100], Loss: 0.1903628408908844\n",
            "Epoch [87/100], Loss: 0.17158527672290802\n",
            "Epoch [88/100], Loss: 0.30564847588539124\n",
            "Epoch [89/100], Loss: 0.3784601390361786\n",
            "Epoch [90/100], Loss: 0.2357415109872818\n",
            "Epoch [91/100], Loss: 0.2021346241235733\n",
            "Epoch [92/100], Loss: 0.37225937843322754\n",
            "Epoch [93/100], Loss: 0.17938555777072906\n",
            "Epoch [94/100], Loss: 0.2283078134059906\n",
            "Epoch [95/100], Loss: 0.1678294688463211\n",
            "Epoch [96/100], Loss: 0.2541053295135498\n",
            "Epoch [97/100], Loss: 0.32826563715934753\n",
            "Epoch [98/100], Loss: 0.14991599321365356\n",
            "Epoch [99/100], Loss: 0.58051997423172\n",
            "Epoch [100/100], Loss: 0.20323871076107025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_inputs = torch.tensor(X_test.values, dtype=torch.float32)\n",
        "    predictions = model(test_inputs).squeeze()"
      ],
      "metadata": {
        "id": "o0S-QEyiNQXT"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(y_test, predictions.numpy())\n",
        "print(mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjXcfPelTuaP",
        "outputId": "eb15ba40-f2de-4154-e41b-05992cf205a3"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2781167201397615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ymBINdrMUVN-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}