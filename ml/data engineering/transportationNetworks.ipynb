{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "import geopandas as gpd\n",
    "import requests \n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_objects_in_polygon(polygon):\n",
    "    if not isinstance(polygon, (Polygon, MultiPolygon)):\n",
    "        raise TypeError(\"Not polygon obj\")\n",
    "\n",
    "    tags = {\n",
    "        'aeroway': 'aerodrome',\n",
    "        'seamark:type': 'harbour',\n",
    "        'highway': 'motorway' #if we set this to True, we will get all roads, this is just highways\n",
    "    }\n",
    "\n",
    "    try:\n",
    "\n",
    "        objects = ox.features_from_polygon(polygon, tags)\n",
    "    except ox._errors.InsufficientResponseError: #specific error is InsufficientResponseError, but osmnx doesn't allow you to import it for some reason\n",
    "        return {\n",
    "        'airports': 0,\n",
    "        'harbors': 0,\n",
    "        'highways': 0\n",
    "    }\n",
    "\n",
    "    num_airports = len(objects[objects['aeroway'] == 'aerodrome']) if 'aeroway' in objects.columns else 0\n",
    "    num_harbors = len(objects[objects['seamark:type'] == 'harbour']) if 'seamark:type' in objects.columns else 0\n",
    "    num_highways = len(objects[objects['highway'].notna()]) if 'highway' in objects.columns else 0\n",
    "\n",
    "\n",
    "    return {\n",
    "        'airports': num_airports,\n",
    "        'harbors': num_harbors,\n",
    "        'highways': num_highways\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bounding_coordinates(place, country): # this is from the vegetation notebook, the current one in the repo is corupt. once its not corupt we can import this func\n",
    "    url = f\"https://nominatim.openstreetmap.org/search.php?q={place}+{country}&polygon_geojson=1&format=json\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        polygon_coordinates = 0\n",
    "        bounding_coordinates = 0\n",
    "        if(data[0][\"class\"] != \"boundary\"):\n",
    "          for i in range(len(data)):\n",
    "            if(data[i][\"class\"] == \"boundary\"):\n",
    "              polygon_coordinates = data[i]['geojson']['coordinates'][0]\n",
    "        else:\n",
    "          polygon_coordinates = data[0]['geojson']['coordinates'][0]\n",
    "        bounding_coordinates = [float(i) for i in data[0]['boundingbox']]\n",
    "        return [polygon_coordinates, bounding_coordinates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_coords(coord_list): #ChatGPT generated FYI, sorry ): , had to run to class\n",
    "    \"\"\" Flatten the list of coordinates to a list of tuples. \"\"\"\n",
    "    # This function should handle nested structures appropriately\n",
    "    if isinstance(coord_list[0], list):\n",
    "        # If the first item is a list, we assume it's a list of lists\n",
    "        if isinstance(coord_list[0][0], list):\n",
    "            # If the nested list also contains a list, recurse deeper\n",
    "            return flatten_coords([item for sublist in coord_list for item in sublist])\n",
    "        else:\n",
    "            # Otherwise, it's just one level deep of coordinate pairs\n",
    "            return [tuple(item) for item in coord_list]\n",
    "    else:\n",
    "        # Base case: if we're at the coordinate pair level, stop flattening\n",
    "        return [tuple(coord_list)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def return_weight(city, country):\n",
    "    poly_coords = bounding_coordinates(city, country)[0]\n",
    "    poly_coords = flatten_coords(poly_coords)\n",
    "    poly = Polygon(poly_coords)\n",
    "\n",
    "\n",
    "    object_counts = count_objects_in_polygon(poly)\n",
    "   \n",
    "\n",
    "    square_surface_area = poly.area\n",
    "\n",
    "\n",
    "    totalSum = 5*(object_counts['airports']) + 3*(object_counts['harbors']) + (object_counts['highways'])\n",
    "\n",
    "    return totalSum/square_surface_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    print(return_weight(\"D\", \"Mozambique\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_transport_network_density(csv_filepath):\n",
    "    # Read the CSV data\n",
    "    with open(csv_filepath, newline='') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        rows = list(reader)  # Convert iterator to list to reuse it\n",
    "\n",
    "    for row in rows:\n",
    "        print(\"Checking:\", row['Region'].replace(\"_\", \" \"), row['Country'].replace(\"_\", \" \"))\n",
    "        result = return_weight(row['Region'].replace(\"_\", \" \"), row['Country'].replace(\"_\", \" \"))\n",
    "        print(row['Region'], row['Country'], result)\n",
    "        row['Transport_Network_Density'] = float(row['Transport_Network_Density']) + result\n",
    "\n",
    "    with open(csv_filepath, 'w', newline='') as file:\n",
    "        fieldnames = rows[0].keys()  # Grab the field names from the first row\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking: Bamingui Central African Republic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.12/site-packages/osmnx/_overpass.py:245: UserWarning: This area is 28 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bamingui Central_African_Republic 4.221284958208782\n",
      "Checking: Bangui Central African Republic\n",
      "Bangui Central_African_Republic 887.2595543923152\n",
      "Checking: Badakhshan Afghanistan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.12/site-packages/osmnx/_overpass.py:245: UserWarning: This area is 34 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Badakhshan Afghanistan 10.228901654130443\n",
      "Checking: Badghis Afghanistan\n",
      "Badghis Afghanistan 2.4421677548779237\n"
     ]
    }
   ],
   "source": [
    "update_transport_network_density(\"/Users/alexforman/Downloads/foodwatchInput.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
